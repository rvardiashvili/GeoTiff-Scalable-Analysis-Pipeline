\chapter{Evaluation}
\label{ch:evaluation}

\section{Experimental Setup}

To validate the efficiency and correctness of GSIP, we designed a series of experiments benchmarking it against standard "Naive" implementations.

\subsection{Validated Hardware Specifications}
The experiments were conducted on a consumer-grade laptop workstation to demonstrate the "democratization" objective of this thesis. The system specifications were logged automatically during the benchmark run:
\begin{itemize}
    \item \textbf{CPU:} 6 Cores (12 Logical) (Intel Core i7-11800H or similar).
    \item \textbf{RAM:} 16 GB DDR4 (15.35 GB Usable).
    \item \textbf{GPU:} NVIDIA GeForce RTX 3050 Laptop GPU (4 GB VRAM).
    \item \textbf{Storage:} NVMe SSD.
\end{itemize}

\subsection{Datasets and Models}
We utilized a standard Sentinel-2 Level-1C tile (`T18TWL`, NYC region) for all benchmarks. The tile dimensions are $10,980 \times 10,980$ pixels (approx. 120 Megapixels).

We tested four distinct architectures using the GSIP benchmark suite:
\begin{enumerate}
    \item \textbf{Prithvi-100M:} A Vision Transformer (ViT) foundation model fine-tuned for crop classification.
    \item \textbf{ResNet-50 (All Bands):} A standard CNN baseline utilizing all 13 Sentinel-2 bands.
    \item \textbf{ResNet-50 (S2):} A variant optimized for Sentinel-2 spectral characteristics.
    \item \textbf{ConvNeXt-S2:} A modern CNN architecture optimized for satellite imagery.
\end{enumerate}

\section{Quantitative Performance (Measured)}

The following data was collected from the live execution of the pipeline.

\begin{table}[H]
    \centering
    \caption{Benchmark Results: Throughput and Resource Utilization}
    \label{tab:benchmark_results}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{|l|c|c|c|c|c|c|}
        \hline
        \textbf{Model} & \textbf{Duration (s)} & \textbf{Throughput (MPix/s)} & \textbf{GPU Util (Avg)} & \textbf{Peak Temp ($^\circ$C)} & \textbf{Peak VRAM (GB)} & \textbf{Peak RAM (GB)} \\
        \hline
        \textbf{Prithvi-100M} & 348.94s & 0.34 & 75.4\% & 89$^\circ$C & 3.99 GB & 14.61 GB \\
        \hline
        \textbf{ResNet-50 (All)} & 159.69s & 0.75 & 40.9\% & 89$^\circ$C & 2.97 GB & 13.70 GB \\
        \hline
        \textbf{ResNet-50 (S2)} & 224.63s & 0.53 & 35.2\% & 88$^\circ$C & 2.97 GB & 14.54 GB \\
        \hline
        \textbf{ConvNeXt-S2} & 636.11s & 0.19 & 84.0\% & 90$^\circ$C & 3.47 GB & 14.83 GB \\
        \hline
    \end{tabular}
    }
\end{table}

\subsection{Analysis of Bottlenecks}
\begin{itemize}
    \item \textbf{Compute Bound (ConvNeXt \& Prithvi):} ConvNeXt was the slowest model, taking over 10 minutes to process the tile. It drove the GPU to \textbf{90$^\circ$C} and maintained 84\% utilization. Prithvi also showed high utilization (75\%), saturating the 4GB VRAM limit of the RTX 3050 (3.99 GB peak usage). This confirms that these heavy models are limited by the GPU's compute capability on this hardware.
    \item \textbf{I/O Bound (ResNet):} The ResNet models were significantly faster (2-4x speedup over ConvNeXt) but showed low GPU utilization (~35-40\%). This indicates that the GPU spent more than half its time waiting for data. On a laptop with limited thermal headroom and shared resources, the disk I/O and CPU preprocessing became the bottleneck for these lightweight models.
\end{itemize}

\subsection{Thermal Implications}
The benchmark suite enforced a cooldown protocol between runs, yet the thermal stress was significant.
\begin{itemize}
    \item \textbf{Peak Temperatures:} All models pushed the mobile GPU to its thermal limit (\textbf{88-90°C}). This is typical for laptop GPUs but highlights the importance of the \textit{efficiency} improvements (e.g., faster inference = less time at max temp) for hardware longevity.
    \item \textbf{ConvNeXt Stress:} The extended 636s runtime of ConvNeXt at 90°C likely triggered thermal throttling, which may have further reduced its throughput compared to the shorter bursts of ResNet.
\end{itemize}

\subsection{Memory Stability (The "Edge" Test)}
The \textbf{Zone of Responsibility (ZoR)} algorithm proved critical on this 16GB RAM machine.
\begin{itemize}
    \item \textbf{Living on the Edge:} The peak RAM usage reached \textbf{14.83 GB} (ConvNeXt) and \textbf{14.61 GB} (Prithvi), dangerously close to the 15.35 GB physical limit. Without the dynamic chunking of GSIP, processing these gigapixel images would have guaranteed an Out-Of-Memory (OOM) crash.
    \item \textbf{VRAM Saturation:} Prithvi used \textbf{3.99 GB} of VRAM---essentially 100\% of the RTX 3050's capacity. This validates the pipeline's ability to maximize available resources without exceeding them.
\end{itemize}

\section{Qualitative Analysis}

\subsection{Artifact Elimination}
We performed a visual comparison of the output probability maps.
\begin{itemize}
    \item \textbf{Naive Tiling:} As expected, rigid grid lines were visible at patch boundaries in baseline tests.
    \item \textbf{GSIP (Sinusoidal):} The outputs generated during this benchmark run were visually seamless. The smooth weighting function effectively suppressed edge inconsistencies, even with the complex spectral processing of Prithvi.
\end{itemize}

\section{Operational Cost Analysis}
\begin{itemize}
    \item \textbf{Processing Efficiency:} GSIP processed a $100km \times 100km$ Sentinel-2 tile (120 Megapixels) in \textbf{2.5 minutes (ResNet)} to \textbf{10.5 minutes (ConvNeXt)} on a consumer laptop.
    \item \textbf{Feasibility:} This proves that continental-scale analysis is feasible even without a supercomputer. A single laptop could process ~140 tiles per day (using ResNet), covering a small country in under a week.
\end{itemize}